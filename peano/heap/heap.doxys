/**

 @dir "Heap"
 
 Peano originally supported solely vertex (and cell) attributes stored and 
 managed by stacks. This proved to be a big disadvantage for two types of 
 applications:
 
 - If there are lots of data assigned to a vertex, the data movements bound to 
   the stack idea are expensive (at least on some machines).
 - If the cardinality of a record assigned to a vertex changes all the time and 
   is neither bound nor known a priori.
   
 Therefore, we introduced a heap concept, i.e. something like vertices holding 
 pointers to records. This page describes how to make a vertex hold multiple 
 instances of class A. The cardinality of this aggregation hereby might change.
 
 
 !!! Modelling A
 
 We consider our Vertex type V holding zero up to any number of instances of 
 class A. For this, we create a new text file called $A.def$. For our example 
 it looks as follows:
 
 \code
   Packed-Type: short int;

   Constant: DIMENSIONS;

   class peano::applications::myApplication::dastgen::A {

      persistent parallelise double x[DIMENSIONS];

   };
 \endcode
 
 This file then is to be translated into a Peano C++ class due to the statement
 \code
 java -jar DaStGen.jar --plugin PeanoSnippetGenerator --naming PeanoNameTranslator VertexData.def my-pde-applications-records-directory
 \endcode
 That's the formal stuff.
 
 !!! Modelling Vertex V
 
 Next, we have to open our vertex's DaStGen file (the specification) and extend 
 the vertex model with an additional integer attribute.
 \code
 ...
 class MyDaStGenVertex {
    ...
    persistent int myAggregateWithArbitraryCardinality;
 }
 \endcode
 The new attribute has to be persistent, i.e. once we've told a vertex that it 
 holds additional attributes it should not forget this, and it is of type 
 integer as we model it as kind of a pointer index. There is no need to mark it 
 as parallelise, as we never exchange indices. We do exchange associated data. 
 
 Please regenerate your vertices either due to an additional DaStGen call or 
 due to a new run of the prototyping tool.    
      
 !!! Behaviour (Sequential)
 
 Finally, we have to add behaviour. In the constructor of the vertex V, we should 
 set the value of myAggregateWithArbitraryCardinality to -1 or another dummy value
 smaller than zero.
 \code
 _vertexData.setMyAggregateWithArbitraryCardinality(-1); 
 \endcode
 
 Next, we have to assign each vertex that shall hold instances of A a valid 
 aggregate number. For this, we use the heap's factory method for numbers. 
 \code
 vertex.setMyAggregateWithArbitraryCardinality(peano::kernel::heap::Heap<A>::getInstance().createData());
 \endcode
 It might be a good idea to do this in the createVertex operations of your 
 mappings. Another opportunity is to check whether a vertex already has a 
 valid aggregate number on-the-fly.
 
 Whenever you wanna manipulate the aggregates, you have to follow a two-step 
 procedure:
 - You fetch the aggregate's number from your vertex due to a $vertex.getMyAggregateWithArbitraryCardinality()$ call.
 - With the result you ask the data heap $peano::kernel::heap::Heap$ for the vector of aggregates.   
 
 !!! MPI Parallelisation
 
 For the parallelisation you basically have to implement 
 prepareSendToNeighbour() and mergeWithNeighbour() and decide there whether you 
 wanna exchange the aggregates or not. While the decision is up to you, the 
 actual exchange is provided by the heap object:   
 
 \code
  void MyMapping::prepareSendToNeighbour(
    V&   vertex,
    int  toRank
  ) {
    if you decide to exchange the aggregates as well {
      peano::kernel::heap::Heap<A>::getInstance().sendBoundaryData(vertex.getMyAggregateWithArbitraryCardinality(), toRank);
    }
  }

  void MyMapping::mergeWithNeighbour(
    V&         vertex, 
    const V&   neighbour, 
    int        fromRank
  ) {
    if you decide to exchange the aggregates as well {
      std::vector< A > neighboursData = peano::kernel::heap::Heap<A>::getInstance().receiveBoundaryData(fromRank);
    
      // and now you have to merge neighboursData with the data associated with vertex
    }
  }
  \endcode
  
  The tricky thing here is that the exchange of information between neighbours is done between
  iterations. I.e. if you send the data in prepareSendToNeighbour in iteration i with mapping m(i)
  you have to receive the data in mergeWithNeighbour in iteration i+1 in mapping m(i+1). 
  

  Since Peano performs load-balancing on the fly an application's implementer never knows when
  the heap data is sent due to forking part of the domain to another node. Thus, a good approach
  is to specify a new mapping in the PeProt script that is merged to all adapters. In this mapping
  (in the following called ForkJoinMapping) only the events prepareSendToNeighbour() and 
  mergeWithNeighbour() are relevant.

   \code
  void ForkJoinMapping::prepareCopyToRemoteNode(
    V&   localVertex,
    int  toRank
  ) {
    peano::kernel::heap::Heap<A>::getInstance().sendBoundaryData(vertex.getMyAggregateWithArbitraryCardinality(), toRank);
  }

  void ForkJoinMapping::mergeWithRemoteDataDueToForkOrJoin (
    V&         localVertex, 
    const V&   remoteVertex, 
    int        fromRank,
  ) {
    std::vector< A > neighboursData = peano::kernel::heap::Heap<A>::getInstance().receiveBoundaryData(fromRank);
        
    //Copy all data to the newly created local vertex
    if(localVertex.getMyAggregateWithArbitraryCardinality() == -1) {
      localVertex.setMyAggregateWithArbitraryCardinality( peano::kernel::heap::Heap<A>::getInstance().createData() );
    }
    std::vector<ExternalVertexData>& localData = peano::kernel::heap::Heap<A>::getInstance().getData(localVertex.getMyAggregateWithArbitraryCardinality());
    
    for(std::vector<ExternalVertexData>::iterator i = remoteData.begin(); i != remoteData.end(); i++) {
      localData.push_back(*i);
    }
  }
  \endcode
  
  To avoid memory leaks the creation and deletion of vertices have to been handled, too. Also the buffered data
  for the asynchronous sends has to be deleted. This is best be done in the
  following way:
  
  \code
  void ForkJoinMapping::destroyVertex (
    Vector<>&   x,
    Vector<>&   h,
    Vertex&     vertex
  ) {
    if(localVertex.vertex.getMyAggregateWithArbitraryCardinality() != -1) {
      peano::kernel::heap::Heap<A>::getInstance().deleteData(vertex.getMyAggregateWithArbitraryCardinality());
    }
  }
  
  void ForkJoinMapping::createInnerVertex(
    Vector<>&  x,
    Vector<>&  h,
    Vertex&    vertex
  ) {
    vertex.setAggregate(-1)
  }


  void ForkJoinMapping::createBoundaryVertex(
    Vector<>&  x,
    Vector<>&  h,
    Vertex&    vertex
  ) {
    vertex.setAggregate(-1)
  }
  
  void ForkJoinMapping::endIteration(
    State&    solverState
  ) {
    peano::kernel::heap::Heap<A>::getInstance().cleanupSends();
  }
  \endcode

  With the approach presented, you can also model multiple aggregates, i.e. 
  vertices holding for example a class A and B of different cardinality. For 
  this, we need two DaStGen models for A and B, and we have to assign the 
  vertex V two integer attributes. Afterwards, we always use two Heap 
  instances for the two different vertices.   
 
 
  !!! Parallel Events
  
  The following image shows the events that are called during the various parallel actions.
  
  \image html MPIEvents.png
 */
 
 