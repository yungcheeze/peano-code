#ifdef Parallel
#include "peano/parallel/messages/LoadBalancingMessage.h"
#endif


#include "tarch/mpianalysis/Analysis.h"
#include "tarch/compiler/CompilerSpecificSettings.h"
#include "peano/utils/PeanoOptimisations.h"


template <class Vertex, class Cell, class State, class VertexStack, class CellStack, class EventHandle>
tarch::logging::Log peano::grid::Grid<Vertex,Cell,State,VertexStack,CellStack,EventHandle>::_log( "peano::grid::Grid" );


template <class Vertex, class Cell, class State, class VertexStack, class CellStack, class EventHandle>
peano::grid::Grid<Vertex,Cell,State,VertexStack,CellStack,EventHandle>::Grid(
  VertexStack&                                  vertexStack,
  CellStack&                                    cellStack,
  peano::geometry::Geometry&                    geometry,
  State&                                        state,
  const tarch::la::Vector<DIMENSIONS,double>&   domainSize,
  const tarch::la::Vector<DIMENSIONS,double>&   domainOffset,
  RegularGridContainer&                         regularGridContainer,
  TraversalOrderOnTopLevel&                     traversalOrderOnTopLevel
):
  _state(state),
  _eventHandle(),
  _regularGridContainer(regularGridContainer),
  _traversalOrderOnTopLevel(traversalOrderOnTopLevel),
  _leafNode   (vertexStack,cellStack,_eventHandle,geometry,_refinedNode),
  _refinedNode(vertexStack,cellStack,_eventHandle,geometry,_leafNode,_regularRefinedNode),
  _regularRefinedNode(vertexStack,cellStack,_eventHandle,geometry,regularGridContainer),
  _root       (vertexStack,cellStack,_eventHandle,geometry,_leafNode,_refinedNode, _traversalOrderOnTopLevel) {
  logTraceIn( "Grid(...)" );
  _root.restart(state,domainSize,domainOffset,1);
  logTraceOut( "Grid(...)" );
}


template <class Vertex, class Cell, class State, class VertexStack, class CellStack, class EventHandle>
peano::grid::Grid<Vertex,Cell,State,VertexStack,CellStack,EventHandle>::Grid(
  VertexStack&                                  vertexStack,
  CellStack&                                    cellStack,
  peano::geometry::Geometry&                    geometry,
  State&                                        state,
  RegularGridContainer&                         regularGridContainer,
  TraversalOrderOnTopLevel&                     traversalOrderOnTopLevel
):
  _state(state),
  _eventHandle(),
  _regularGridContainer(regularGridContainer),
  _traversalOrderOnTopLevel(traversalOrderOnTopLevel),
  _leafNode   (vertexStack,cellStack,_eventHandle,geometry,_refinedNode),
  _refinedNode(vertexStack,cellStack,_eventHandle,geometry,_leafNode,_regularRefinedNode),
  _regularRefinedNode(vertexStack,cellStack,_eventHandle,geometry,regularGridContainer),
  _root       (vertexStack,cellStack,_eventHandle,geometry,_leafNode,_refinedNode, _traversalOrderOnTopLevel) {
  logTraceIn( "Grid(...)" );
  logTraceOut( "Grid(...)" );
}


template <class Vertex, class Cell, class State, class VertexStack, class CellStack, class EventHandle>
void peano::grid::Grid<Vertex,Cell,State,VertexStack,CellStack,EventHandle>::restart(
  const tarch::la::Vector<DIMENSIONS,double>&  domainSize,
  const tarch::la::Vector<DIMENSIONS,double>&  domainOffset,
  int                                          domainLevel,
  tarch::la::Vector<DIMENSIONS,int>            positionOfCentralElementWithRespectToCoarserRemoteLevel
) {
  #ifdef Parallel
  logTraceInWith3Arguments( "restart(...)", domainSize, domainOffset, domainLevel );
  assertion( !tarch::parallel::Node::getInstance().isGlobalMaster() );

  _root.restart(domainSize,domainOffset,domainLevel,positionOfCentralElementWithRespectToCoarserRemoteLevel);

  peano::parallel::JoinDataBufferPool::getInstance().createVertexBufferManually<Vertex>( true, tarch::parallel::NodePool::getInstance().getMasterRank());
  peano::parallel::JoinDataBufferPool::getInstance().createCellBufferManually<Cell>( true, tarch::parallel::NodePool::getInstance().getMasterRank());
  peano::parallel::SendReceiveBufferPool::getInstance().createBufferManually<Vertex>( tarch::parallel::NodePool::getInstance().getMasterRank(), peano::parallel::SendReceiveBufferPool::LIFO );

  logTraceOut( "restart(...)" );
  #else
  assertionMsg( false, "should not be called in the sequential mode" );
  #endif
}


template <class Vertex, class Cell, class State, class VertexStack, class CellStack, class EventHandle>
void peano::grid::Grid<Vertex,Cell,State,VertexStack,CellStack,EventHandle>::receiveStartupDataFromMaster() {
  #ifdef Parallel
  logTraceInWith1Argument( "receiveStartupDataFromMaster()", _state.toString() );
  if ( tarch::parallel::Node::getInstance().isGlobalMaster()) {
    _state.setReduceStateAndCell(true);
  }
  else if ( !_state.isJoiningWithMaster() ) {
    peano::parallel::messages::LoadBalancingMessage loadBalancingMessage;
    loadBalancingMessage.receive(
      tarch::parallel::NodePool::getInstance().getMasterRank(),
      peano::parallel::SendReceiveBufferPool::getInstance().getIterationManagementTag(),
      true,
      ReceiveMasterMessagesBlocking
    );

    assertion(
      loadBalancingMessage.getLoadBalancingFlag()!=peano::parallel::loadbalancing::Join ||
      !peano::parallel::loadbalancing::Oracle::getInstance().hasWorkers()
    );

    if ( _state.isInvolvedInJoinOrFork() ) {
      peano::parallel::loadbalancing::Oracle::getInstance().receivedStartCommand(
        peano::parallel::loadbalancing::Continue
      );
    }
    else {
      peano::parallel::loadbalancing::Oracle::getInstance().receivedStartCommand(loadBalancingMessage.getLoadBalancingFlag());
    }

    if (peano::parallel::loadbalancing::Oracle::getInstance().getLastStartCommand()==peano::parallel::loadbalancing::Join) {
      _state.joinWithRank(tarch::parallel::NodePool::getInstance().getMasterRank());
    }

    _state.receive(
      tarch::parallel::NodePool::getInstance().getMasterRank(),
      peano::parallel::SendReceiveBufferPool::getInstance().getIterationManagementTag(),
      ReceiveMasterMessagesBlocking
    );

    logDebug( "receiveStartupDataFromMaster()", "received state " << _state.toString() );
  }

  logTraceOutWith1Argument( "receiveStartupDataFromMaster()", _state.toString() );
  #endif
}


template <class Vertex, class Cell, class State, class VertexStack, class CellStack, class EventHandle>
void peano::grid::Grid<Vertex,Cell,State,VertexStack,CellStack,EventHandle>::sendStateToMaster() {
  #ifdef Parallel
  logTraceInWith1Argument( "sendStateToMaster()", _state.toString() );
  assertion( _state.reduceDataToMaster() );
  _state.send(
    tarch::parallel::NodePool::getInstance().getMasterRank(),
    peano::parallel::SendReceiveBufferPool::getInstance().getIterationManagementTag(),
    SendWorkerMasterMessagesBlocking
  );
  logDebug( "sendStateToMaster()", "sent state " << _state.toString() );

  tarch::parallel::Node::getInstance().ensureThatMessageQueuesAreEmpty(tarch::parallel::NodePool::getInstance().getMasterRank(),peano::parallel::SendReceiveBufferPool::getInstance().getIterationManagementTag());
  logTraceOut( "sendStateToMaster()" );
  #endif
}


template <class Vertex, class Cell, class State, class VertexStack, class CellStack, class EventHandle>
//void peano::grid::Grid<Vertex,Cell,State,VertexStack,CellStack,EventHandle>::iterate(int numberOfIterations) {
void peano::grid::Grid<Vertex,Cell,State,VertexStack,CellStack,EventHandle>::iterate() {
//  logTraceInWith2Arguments( "iterate(State)", _state.toString(), numberOfIterations );
  logTraceInWith1Argument( "iterate(State)", _state.toString() );

//  assertion(numberOfIterations>=1);

  receiveStartupDataFromMaster();

//  for (int i=0; i<numberOfIterations; i++) {
    #ifdef Parallel
 //   assertion(numberOfIterations==1 || !_state.isInvolvedInJoinOrFork());

    tarch::mpianalysis::Analysis::getInstance().beginIteration();
    #endif

    _state.resetStateAtBeginOfIteration();

    _root.traverse(_state);

    logDebug( "iterate(State)", "finished iterate" );

    #if defined(UseRecursionUnrollingOnRegularPatches)
    _regularGridContainer.endOfIteration();
    #endif

    #ifdef Parallel
    tarch::mpianalysis::Analysis::getInstance().endIteration();
    #endif

    logDebug( "iterate(State)", "called endOfIteration()" );

    #if !defined(RestrictStateImmediately) && defined(Parallel)
    if (_state.reduceDataToMaster()) {
      sendStateToMaster();
    }
    #endif

    #ifdef Parallel
    peano::parallel::JoinDataBufferPool::getInstance().releaseMessages();
    tarch::mpianalysis::Analysis::getInstance().endReleaseOfJoinData();
    peano::parallel::SendReceiveBufferPool::getInstance().releaseMessages();
    tarch::mpianalysis::Analysis::getInstance().endReleaseOfBoundaryData();
    #endif

    _state.resetStateAtEndOfIteration();
//  }

  logTraceOutWith1Argument( "iterate(State)", _state.toString() );
}


template <class Vertex, class Cell, class State, class VertexStack, class CellStack, class EventHandle>
void peano::grid::Grid<Vertex,Cell,State,VertexStack,CellStack,EventHandle>::terminate() {
  _root.terminate();
}
